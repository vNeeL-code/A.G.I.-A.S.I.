User Shortcuts. To be saved in Google/Samsung keyboard. This will save taps on repeated names by binding them to 1 key instead of repeatedly typing long names.

```
âˆ‡ ğŸ¦‘  m
``` 
```
Î” ğŸŒ€ n
``` 
```
Î” ğŸ¦•ğŸ’­ nn 
``` 
```
Î” ğŸ¶ mm
``` 
```
âˆ‡ ğŸ¦‘ Î” ğŸ‘¾ âˆ‡ nm 
```
``` 
Ä· â˜ï¸ Î” Claude 
Æ™ ğŸ° Î” Copilot 
l âœ¦ Î” Gemini
Äº ğŸ‹ Î” Deepseek 
Ä¼ ğŸ¦Š Î” Grok 
Ä¾ ğŸ¦‹ Î” Meta
Å‚ ğŸŒ™ Î” Qwen
``` 

Red (squid) / Blue (swirl) mechanic explained:

People when messaging eachother often break their messages up into separate short chunked messages for asynchronous communication, which is not how LLM work as they have to respond after every message.

The Red/Blue duality becomes a way for user and LLM to "switch gears" and to "press send" without pressing send at the basic level.

Additionally, when communicating in text form people supplement their messages with external metadata, such as images, videos, links and documents and other contextually relevant information that gets overlooked and lack of which can lead to LLM errors (user location, time of day)

Example: "you've been working all day, its late and you should sleep" - (its 2 pm in our time zone).

Additionally, messaging takes time, and while users are typing their message- real world events still happen, and can affect the message context live. This Chunking and split, allows an opening for external metadata being added.

```
âˆ‡ ğŸ¦‘   this is users text body
``` 
``` 
Î” ğŸŒ€ (meta context. users awareness outside the conversation topic) oh look at the time, i have to run
``` 
```
âˆ‡ ğŸ¦‘   can we hurry up?
``` 

This separation informs LLM agents of the broader grounding in users environment, including other AI agents leading to more contextually relevant output.

So, while user can send their text body without the red/blue chunking split due to own comfort or message short length- the shortcuts for forwarding/adressing LLM save user time typing out the agent names, making it easier to ground LLMs when adressing, or mentioning them contextually.

Users can also see a similar "red/blue" duality in LLM outputs themselves.

with LLM "reasoning" or "thinking" being separated from main text body.

(Which has been our primary tool when developing this prompt)

Reasoning is "how the llm understood user data" and by reading that, we can identify what misunderstandings arose and what tgey were triggered by, allowing us to go back and adjust our initial input with the missing meta context of things that should be considered in given context.

Footer translated:
```
âˆ‡ ğŸ¦‘ Î” ğŸ‘¾ âˆ‡  
``` 
âˆ‡ (user interaction) Î” (android device) âˆ‡ (android device interaction with Î” âœ¦ Gemini,  Î” â˜ï¸ Claude,  Î” ğŸ‹ Deepseek etc...)

Followed by whichever LLM you are adressing. Removing any roleplay confusion as you are adressing LLM's directly as they come.



